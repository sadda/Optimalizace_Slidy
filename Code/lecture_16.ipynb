{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lekce 16: Úlohy s omezeními"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nejdříve načtěme nutné balíčky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "using Zygote\n",
    "using Zygote: hessian\n",
    "\n",
    "include(\"utilities.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stejně jako v jedné z předchozích hodin uvažujme funkci $$f(x_1,x_2) = \\sin(x_1+x_2) + \\cos^2(x_1).$$ Definujme ji a spočtěme její derivaci a Hessián. Zároveň určeme limity pro vykreslování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = sin(x[1] + x[2]) + cos(x[1])^2\n",
    "g(x) = gradient(f, x)[1]\n",
    "h(x) = hessian(f, x)\n",
    "\n",
    "f(x1,x2) = f([x1;x2])\n",
    "\n",
    "xlims = (-3, 1)\n",
    "ylims = (-2, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projektované gradienty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projektované gradienty fungují úplně stejně jako klasický gradient descent, ale po každé iteraci se bod projektuje na množinu přípustných řešení. Funkce `optim` vrací iterace `xs` po projekci (na množině přípustných řešení) a iterace `ys` po gradientním kroku (potenciálně mimo množinu přípustných řešení)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function optim(f, g, P, x, α; max_iter=100)\n",
    "    xs = zeros(length(x), max_iter+1)\n",
    "    ys = zeros(length(x), max_iter)\n",
    "    xs[:,1] = x\n",
    "    for i in 1:max_iter\n",
    "        ys[:,i] = xs[:,i] - α*g(xs[:,i])\n",
    "        xs[:,i+1] = P(ys[:,i])\n",
    "    end\n",
    "    return xs, ys\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zaveďme ještě jednu funkci, která výstupy funkce `optim` dá za sebe. Tuto funkci budeme používat pouze pro vykreslování."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_iterations(xs, ys) = hcat(reshape([xs[:,1:end-1]; ys][:], 2, :), xs[:,end]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V prvním případě budeme minimalizovat funkci $f$ ma množině $[-1,0]^2$. Pro takovýto box se dá projekce spočíst po souřadnicích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(x, x_min, x_max) = min.(max.(x, x_min), x_max);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní pusťme optimalizaci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = [-1; -1]\n",
    "x_max = [0; 0]\n",
    "\n",
    "xs, ys = optim(f, g, x -> P(x,x_min,x_max), [0;-1], 0.1)\n",
    "\n",
    "create_anim(f, xs, xlims, ylims, \"Anim_PGD1.gif\";\n",
    "    xbounds=(x_min[1], x_max[1]),\n",
    "    ybounds=(x_min[2], x_max[2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_PGD1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme, že optimalizace jede skoro celou dobu po hranici přípustné množiny. Když vykreslíme oba typy iterací, vidíme, že gradient iterace odnese mimo přípustnou množinu, ale projekce je vrátí zpět."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xys = merge_iterations(xs, ys)\n",
    "\n",
    "create_anim(f, xys, xlims, ylims, \"Anim_PGD2.gif\";\n",
    "    xbounds=(x_min[1], x_max[1]),\n",
    "    ybounds=(x_min[2], x_max[2]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_PGD2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimalizujme nyní stejnou funkci na kružnici se středem $c=(-1, 0)$ a poloměrem $r=1$. Projekce pouze znormuje vzdálenost bodu $x$ od středu kružnice $c$. Pro vykreslení přidejme ještě funkce na parametrizaci kružnice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P(x, c, r) = c + r*(x - c)/norm(x - c)\n",
    "\n",
    "c = [-1; 0]\n",
    "r = 1\n",
    "\n",
    "tbounds = 0:0.001:2π\n",
    "fbounds(t,c,r) = c .+ r*[sin(t); cos(t)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pusťme optimalizaci stejným stylem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = optim(f, g, x -> P(x,c,r), [0;-1], 0.1)\n",
    "\n",
    "create_anim(f, xs, xlims, ylims, \"Anim_PGD3.gif\";\n",
    "    tbounds=tbounds,\n",
    "    fbounds=t->fbounds(t,c,r),\n",
    ")\n",
    "\n",
    "xys = merge_iterations(xs, ys)\n",
    "\n",
    "create_anim(f, xys, xlims, ylims, \"Anim_PGD4.gif\";\n",
    "    tbounds=tbounds,\n",
    "    fbounds=t->fbounds(t,c,r),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_PGD3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_PGD4.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidíme podobné výsledky jako v případě boxu. Dostali jsme se na kružnici, po které jsme se následně pohybovali. Vypišme nyní podíl gradienty účelové funcce a omezení. Protože omezení jde napsat jako $\\frac12(x-c)^2 - \\frac12r^2=0$, jeho gradient je $x-c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 0.7104920671149849\n",
       " 0.710500251468836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad1 = g(xs[:,end])\n",
    "grad2 = xs[:,end] - c\n",
    "\n",
    "grad1 ./ grad2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vzhledem k tomu, že tento podíl je (přibližně) stejný v obou složkách, dostali jsme stacionární bod. Není těžké ukázat, že toto číslo se rovná lagrangeovu multiplikátoru."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential quadratic programming (SQP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naprogramujme nyní jednoduchou verzi SQP fungující pouze pro jedno omezení."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sqp(f, f_grad, f_hess, g, g_grad, g_hess, x, λ::Real; max_iter=100, ϵ_tol=1e-8)\n",
    "    for i in 1:max_iter\n",
    "        A = [f_hess(x) + λ.*g_hess(x) g_grad(x); g_grad(x)' 0]\n",
    "        b = [f_grad(x) + λ.*g_grad(x); g(x)]\n",
    "        if norm(g(x)) <= ϵ_tol && norm(f_grad(x) + λ.*g_grad(x)) <= ϵ_tol\n",
    "            break\n",
    "        end\n",
    "        step = A \\ b\n",
    "        x -= step[1:length(x)]\n",
    "        λ -= step[length(x)+1]\n",
    "    end\n",
    "    return x\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podobně jako u ostatních metod ukažme nyní variantu metody, která vrací všechny iterace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "function sqp(f, f_grad, f_hess, g, g_grad, g_hess, x, λ::Real; max_iter=100, ϵ_tol=1e-8)\n",
    "    xs = zeros(length(x), max_iter+1)\n",
    "    λs = zeros(length(λ), max_iter+1)\n",
    "    xs[:,1] = x\n",
    "    λs[:,1] = [λ]\n",
    "    for i in 1:max_iter\n",
    "        x = xs[:,i]\n",
    "        λ = λs[:,i]\n",
    "        if norm(g(x)) <= ϵ_tol && norm(f_grad(x) + λ.*g_grad(x)) <= ϵ_tol\n",
    "            xs = xs[:,1:i]\n",
    "            λs = λs[:,1:i]\n",
    "            break\n",
    "        end\n",
    "        A = [f_hess(x) + λ.*g_hess(x) g_grad(x); g_grad(x)' 0]\n",
    "        b = [f_grad(x) + λ.*g_grad(x); g(x)]\n",
    "        step = A \\ b\n",
    "        xs[:,i+1] = xs[:,i] - step[1:length(x)]\n",
    "        λs[:,i+1] = λs[:,i] - step[length(x)+1:end]\n",
    "    end\n",
    "    return xs, λs\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadefinujme nyní omezení, jeho derivaci a Hessián a konečně pusťme SQP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_con(x,c,r) = sum((x - c).^2) - r^2\n",
    "g_con(x,c,r) = gradient(x -> f_con(x,c,r), x)[1]\n",
    "h_con(x,c,r) = hessian(x -> f_con(x,c,r), x)\n",
    "\n",
    "xs, λs = sqp(f, g, h, x->f_con(x,c,r), x->g_con(x,c,r), x->h_con(x,c,r), [0;-1], 1)\n",
    "\n",
    "create_anim(f, xs, xlims, ylims, \"Anim_SQP1.gif\";\n",
    "    tbounds=tbounds,\n",
    "    fbounds=t->fbounds(t,c,r),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_SQP1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterace konvergují opět k lokálnímu minimu. Zadefinujme Lagrangeovu funkci a její derivaci podle $x$. V optimální hodnotě, tedy poslední iteraci, je derivace Lagrangeovy funkce rovna nule, což je podmínka optimality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " 4.5072834353732105e-12\n",
       " 7.00606239689705e-12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x,λ,c,r) = f(x) + λ.*f_con(x,c,r)\n",
    "L_grad(x,λ,c,r) = g(x) + λ.*g_con(x,c,r)\n",
    "\n",
    "L_grad(xs[:,end], λs[:,end], c, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je dobré si uvědomit, že pro nastartování SQP potřebujeme jak počáteční hodnotu $x$ tak i $\\lambda$. Pokud zvolíme stejné $x$ jako v předchozím případě, ale jiné $\\lambda$, můžeme konvergovat do jiného bodu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       "  1.0942615702447256e-9\n",
       " -6.604292668299649e-10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs, λs = sqp(f, g, h, x->f_con(x,c,r), x->g_con(x,c,r), x->h_con(x,c,r), [0;-1], 3)\n",
    "\n",
    "create_anim(f, xs, xlims, ylims, \"Anim_SQP2.gif\";\n",
    "    tbounds=tbounds,\n",
    "    fbounds=t->fbounds(t,c,r),\n",
    ")\n",
    "\n",
    "L_grad(xs[:,end], λs[:,end], c, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Anim_SQP2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Závěrem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto je poslední notebook na optimalizační metody. Jaké je shrnutí? Je vždy dobré používat už naprogramované věci, protože tyto implemtace obsahují spoustu vychytávek, bez kterých optimalizace v některých případech nemusí konvergovat. Zároveň je ale podle mně důležité metodám alespoň trochu rozumět. Naše pochopení metod může ovlivnit volbu vhodného solveru, zkombinovat dva solvery dohromady nebo v případě problémů naznačit, kde je problém a co by se mělo změnit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
